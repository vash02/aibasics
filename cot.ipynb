{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T08:09:34.565218Z",
     "start_time": "2025-05-26T08:09:33.932991Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torch transformers protobuf sentencepiece",
   "id": "d7d2d46f9c6700f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv1/lib/python3.10/site-packages (2.7.0)\r\n",
      "Requirement already satisfied: transformers in ./.venv1/lib/python3.10/site-packages (4.52.3)\r\n",
      "Requirement already satisfied: protobuf in ./.venv1/lib/python3.10/site-packages (6.31.0)\r\n",
      "Requirement already satisfied: sentencepiece in ./.venv1/lib/python3.10/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: filelock in ./.venv1/lib/python3.10/site-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv1/lib/python3.10/site-packages (from torch) (4.13.2)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv1/lib/python3.10/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in ./.venv1/lib/python3.10/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv1/lib/python3.10/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in ./.venv1/lib/python3.10/site-packages (from torch) (2025.5.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv1/lib/python3.10/site-packages (from transformers) (0.32.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv1/lib/python3.10/site-packages (from transformers) (2.2.6)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv1/lib/python3.10/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv1/lib/python3.10/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv1/lib/python3.10/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in ./.venv1/lib/python3.10/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv1/lib/python3.10/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv1/lib/python3.10/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv1/lib/python3.10/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv1/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv1/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv1/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv1/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv1/lib/python3.10/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv1/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv1/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T08:09:35.472300Z",
     "start_time": "2025-05-26T08:09:34.647410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n"
   ],
   "id": "c6159e76a0eb866f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-26T08:09:40.623945Z",
     "start_time": "2025-05-26T08:09:35.479028Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"google/flan-t5-small\"\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Make sure sentencepiece is installed and use the slow tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "question = \"John is twice as old as Mary. Mary is 10 years old. How old is John?\"\n",
    "prompt = f\"Q: {question}\\nA: Let's think step by step.\\n\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"=== Chain of Thought Reasoning ===\")\n",
    "print(result)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaibhav/PycharmProjects/workfile/.venv1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chain of Thought Reasoning ===\n",
      "Mary is 10 - 10 = 10 years old. John is 10 - 10 = 10 years old. The answer: 10.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T12:13:20.850080Z",
     "start_time": "2025-05-29T12:13:19.117294Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install bertviz transformers sentencepiece protobuf",
   "id": "8966bca7c5b6ac7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertviz in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (1.4.0)\r\n",
      "Requirement already satisfied: transformers in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (4.52.3)\r\n",
      "Requirement already satisfied: sentencepiece in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (0.2.0)\r\n",
      "Collecting protobuf\r\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\r\n",
      "Requirement already satisfied: torch>=1.0 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from bertviz) (2.7.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from bertviz) (4.67.1)\r\n",
      "Requirement already satisfied: boto3 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from bertviz) (1.38.24)\r\n",
      "Requirement already satisfied: requests in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from bertviz) (2.32.3)\r\n",
      "Requirement already satisfied: regex in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from bertviz) (2024.11.6)\r\n",
      "Requirement already satisfied: filelock in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from transformers) (0.32.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from transformers) (2.2.6)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from transformers) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from torch>=1.0->bertviz) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from torch>=1.0->bertviz) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from torch>=1.0->bertviz) (3.1.6)\r\n",
      "Requirement already satisfied: botocore<1.39.0,>=1.38.24 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from boto3->bertviz) (1.38.24)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from boto3->bertviz) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from boto3->bertviz) (0.13.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from requests->bertviz) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from requests->bertviz) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from requests->bertviz) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from requests->bertviz) (2025.4.26)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from botocore<1.39.0,>=1.38.24->boto3->bertviz) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.0->bertviz) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.0->bertviz) (3.0.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/vaibhav/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.24->boto3->bertviz) (1.17.0)\r\n",
      "Downloading protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl (425 kB)\r\n",
      "Installing collected packages: protobuf\r\n",
      "Successfully installed protobuf-6.31.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T12:16:17.774022Z",
     "start_time": "2025-05-29T12:13:24.668223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from bertviz import head_view\n",
    "import torch\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# CoT prompt\n",
    "question = \"Tom has 5 pencils, gives 2 to Jerry, and then buys 3 more. How many pencils does he have?\"\n",
    "prompt = f\"Q: {question}\\nA: Let's think step by step.\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Generate with attention\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        output_attentions=True,\n",
    "        return_dict_in_generate=True\n",
    "    )\n",
    "\n",
    "# Collect tokenized output\n",
    "tokens = tokenizer.convert_ids_to_tokens(outputs.sequences[0])\n",
    "\n",
    "outputs = model(**inputs, output_attentions=True)\n",
    "\n",
    "# Extract encoder-decoder attention from last layer\n",
    "encoder_decoder_attn = outputs.cross_attentions[-1][0].detach().cpu()\n",
    "\n",
    "# Visualize with BERTViz\n",
    "head_view(encoder_decoder_attn, tokens[:len(inputs['input_ids'][0])], tokens)\n"
   ],
   "id": "7a553e4ca0e824c0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 32.72s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 20.25 GB, other allocations: 464.00 KB, max allowed: 20.40 GB). Tried to allocate 172.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m      9\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmps\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mmps\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# CoT prompt\u001B[39;00m\n\u001B[1;32m     13\u001B[0m question \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTom has 5 pencils, gives 2 to Jerry, and then buys 3 more. How many pencils does he have?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:3850\u001B[0m, in \u001B[0;36mPreTrainedModel.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3845\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dtype_present_in_args:\n\u001B[1;32m   3846\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   3847\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3848\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3849\u001B[0m         )\n\u001B[0;32m-> 3850\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1355\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1352\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1353\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m-> 1355\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    914\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 915\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    918\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    919\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    920\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    925\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    926\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    914\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 915\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    918\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    919\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    920\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    925\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    926\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "    \u001B[0;31m[... skipping similar frames: Module._apply at line 915 (2 times)]\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    914\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 915\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    918\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    919\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    920\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    925\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    926\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:942\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    938\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    939\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    940\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    941\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 942\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    943\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    945\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/research-rep-agent/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1341\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1334\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1335\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[1;32m   1336\u001B[0m             device,\n\u001B[1;32m   1337\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1338\u001B[0m             non_blocking,\n\u001B[1;32m   1339\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[1;32m   1340\u001B[0m         )\n\u001B[0;32m-> 1341\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1342\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1343\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1344\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1345\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1346\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1347\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS backend out of memory (MPS allocated: 20.25 GB, other allocations: 464.00 KB, max allowed: 20.40 GB). Tried to allocate 172.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1c479978c116d09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
